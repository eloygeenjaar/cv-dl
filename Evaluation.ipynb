{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Evaluation.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "G5cHzVSrJUYA",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from sklearn.utils.linear_assignment_ import linear_assignment\n",
        "from sklearn.metrics import confusion_matrix\n",
        "\n",
        "def get_confusion_matrix(gtruth_labels, predicted_labels):\n",
        "  conf_matrix = confusion_matrix(gtruth_labels, predicted_labels)\n",
        "  return conf_matrix\n",
        "\n",
        "def cost_matrix(confusion_matrix=conf_matrix):  \n",
        "    return conf_matrix.max() - conf_matrix \n",
        "\n",
        "def apply_hungarian(conf_matrix):\n",
        "    reorder = []\n",
        "    indexes = linear_assignment(cost_matrix(conf_matrix))\n",
        "    sorted_indexes = sorted(indexes, key=lambda x: x[0])\n",
        "    for e in sorted_indexes:\n",
        "      reorder.append(e[1]) \n",
        "    return reorder\n",
        "    \n",
        "def get_accuracy(gtruth_labels, predicted_labels):\n",
        "    conf_matrix = get_confusion_matrix(gtruth_labels, predicted_labels)\n",
        "    reorder = apply_hungarian(conf_matrix)\n",
        "    new_conf_matrix = conf_matrix[:, reorder]\n",
        "    accuracy = np.trace(new_conf_matrix) / np.sum(new_conf_matrix)\n",
        "    print(accuracy)\n",
        "\n",
        "#Run this command where labels is your ground-truth labels, and predicted labels are your predicted labels\n",
        "# To get predicted labels => Kmeans.labels_\n",
        "\n",
        "get_accuracy(gtruth_labels=labels, predicted_labels=label_pred_l2)"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}